{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7db7ea2-b6d3-4ca2-b5b4-a456c8c6f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Tuple\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pykakasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15873eea-d715-45e9-bb63-4e5299d4c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsJapanese(text):\n",
    "    re_kanji = re.compile(r'[\\u3000-\\u303f\\u3040-\\u309f\\u30a0-\\u30ff\\uff00-\\uff9f\\u4e00-\\u9faf\\u3400-\\u4dbf]')\n",
    "    return re_kanji.search(text) is not None;\n",
    "\n",
    "def containsKanji(text):\n",
    "    re_kanji = re.compile(r'[\\u4e00-\\u9faf\\u3400-\\u4dbf]')\n",
    "    return re_kanji.search(text) is not None;\n",
    "\n",
    "def containsHiragana(text):\n",
    "    re_hiragana = re.compile(r'[\\u3040-\\u309f]')\n",
    "    return re_hiragana.search(text) is not None;\n",
    "\n",
    "def get_state(text):\n",
    "    if containsKanji(text):\n",
    "        return 'kanji'\n",
    "    elif containsHiragana(text):\n",
    "        return 'hiragana'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "def insert_spaces(text):\n",
    "    result = \"\"\n",
    "    state = get_state(text[0])\n",
    "    i = 0\n",
    "    length = len(text)\n",
    "    while i < length:\n",
    "        if state != get_state(text[i]):\n",
    "            state = get_state(text[i])\n",
    "            result += ' '\n",
    "        result += text[i]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "def random_hiragana():\n",
    "    hiragana_list = ['ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'を', 'ん', 'ゔ']\n",
    "    rand_choice_idx = random.randint(0, len(hiragana_list) - 1)\n",
    "    return hiragana_list[rand_choice_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc577d1-9fa3-43e3-8a30-6e9a25519c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('JMdict_e.json') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864b23fc-1e5f-4a95-923b-719240edba4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209106"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43ab7e1-63a2-42a3-a7e3-7baaa57c340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-kanji entries\n",
    "filtered_data = [entry for entry in raw_data if 'k_ele' in entry.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98344d49-b03f-4327-8bf9-15c91ebe4d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168741"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7894e0-e100-444d-8255-c65ee7f6fc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ent_seq': ['1000260'],\n",
       " 'k_ele': [{'keb': ['悪どい'], 'ke_inf': ['&ateji;']},\n",
       "  {'keb': ['灰汁どい'], 'ke_inf': ['&rK;']}],\n",
       " 'r_ele': [{'reb': ['あくどい']}],\n",
       " 'sense': [{'pos': ['&adj-i;'],\n",
       "   'xref': ['あくが強い・2'],\n",
       "   'misc': ['&uk;'],\n",
       "   'gloss': ['gaudy', 'showy', 'garish', 'loud']},\n",
       "  {'pos': ['&adj-i;'],\n",
       "   'misc': ['&uk;'],\n",
       "   'gloss': ['crooked',\n",
       "    'vicious',\n",
       "    'wicked',\n",
       "    'nasty',\n",
       "    'unscrupulous',\n",
       "    'dishonest']}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1120d5c2-5072-462b-a25f-d7f3993afcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for entry in filtered_data:\n",
    "    for k_ele in entry['k_ele']:\n",
    "        kanji = k_ele['keb'][0]\n",
    "        ruby = entry['r_ele'][0]['reb'][0]\n",
    "        if kanji not in data_dict.keys():\n",
    "            data_dict[kanji] = ruby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1d5765-13a5-4998-88e2-b0266992f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'なんで'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['何で']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcf28f-5ccf-4054-a8e5-a2e97e03356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(data_dict.keys())[:50]:\n",
    "    print(key, data_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8260703-acad-44d9-82f4-8a6ada0e5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5_000_000\n",
    "\n",
    "sample_n_options = [1,2,3]\n",
    "sample_n_weights = [85,10,5]\n",
    "sample_n_list = random.choices(sample_n_options, weights=sample_n_weights, k=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3e900-44bd-46fa-9dd9-5db958a3020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "dict_length = len(data_dict)\n",
    "dict_keys = list(data_dict.keys())\n",
    "for sample_n in sample_n_list:\n",
    "    sample_context = []\n",
    "    sample_target = []\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        rand_hiragana = random_hiragana()\n",
    "        sample_context.append(rand_hiragana)\n",
    "        sample_target.append(rand_hiragana)\n",
    "    \n",
    "    for i in range(sample_n):\n",
    "        rand_entry_idx = random.randint(0, dict_length - 1)\n",
    "        rand_entry_key = dict_keys[rand_entry_idx]\n",
    "        rand_entry_value = data_dict[rand_entry_key]\n",
    "        sample_context.append(rand_entry_key)\n",
    "        sample_target.append(rand_entry_value)\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        rand_hiragana = random_hiragana()\n",
    "        sample_context.append(rand_hiragana)\n",
    "        sample_target.append(rand_hiragana)\n",
    "    \n",
    "    data_list.append(''.join(sample_context) + '|' + ''.join(sample_target) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c878d7-7f86-48c3-af6a-a32bca502ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1e797-00c0-469d-9567-a60795dca210",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18947a-52f3-416f-ab40-73dd1cf9c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = 'furigana_training_data.txt'\n",
    "output = open(local_path, 'w')\n",
    "output.writelines(data_list)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c5730-8210-425d-9498-464b0836f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    \n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('|') for line in lines]\n",
    "    \n",
    "    context = np.array([context for target, context in pairs])\n",
    "    target = np.array([target for target, context in pairs])\n",
    "    \n",
    "    return target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a91e3-5856-41fe-83fd-686800173626",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = pathlib.Path(local_path)\n",
    "context, target = load_data(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7091fe2-cdab-4ca4-81a8-5927fd628e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
